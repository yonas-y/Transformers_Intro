{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-15T18:50:10.058009Z",
     "start_time": "2025-05-15T18:50:05.132917Z"
    }
   },
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress INFO and WARNING logs\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 21:50:07.435929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747335007.495179    1115 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747335007.510079    1115 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747335007.581437    1115 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747335007.581522    1115 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747335007.581526    1115 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747335007.581527    1115 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T18:50:23.517155Z",
     "start_time": "2025-05-15T18:50:20.211965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use TensorFlow Datasets to load the Portuguese-English translation dataset!!!\n",
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',  with_info=True, as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ],
   "id": "dbe59a2e931eb50c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1747335023.057326    1115 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1747335023.070343    1115 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T18:50:39.054360Z",
     "start_time": "2025-05-15T18:50:38.758734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preview_translation_examples(dataset, batch_size: int = 5, num_batches: int = 1):\n",
    "    \"\"\"\n",
    "    Prints sample translation examples from the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: A `tf.data.Dataset` yielding (pt, en) translation pairs.\n",
    "        batch_size (int): Number of examples per batch to preview.\n",
    "        num_batches (int): Number of batches to preview.\n",
    "    \"\"\"\n",
    "    for batch_num, (pt_batch, en_batch) in enumerate(dataset.batch(batch_size).take(num_batches), start=1):\n",
    "        print(f'--- Batch {batch_num} ---')\n",
    "        for pt, en in zip(pt_batch.numpy(), en_batch.numpy()):\n",
    "            print(f'Portuguese: {pt.decode(\"utf-8\")}')\n",
    "            print(f'English   : {en.decode(\"utf-8\")}\\n')\n",
    "\n",
    "# Usage\n",
    "preview_translation_examples(train_examples)"
   ],
   "id": "223df1ac950ec9ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Batch 1 ---\n",
      "Portuguese: e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "English   : and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "\n",
      "Portuguese: mas e se estes fatores fossem ativos ?\n",
      "English   : but what if it were active ?\n",
      "\n",
      "Portuguese: mas eles não tinham a curiosidade de me testar .\n",
      "English   : but they did n't test for curiosity .\n",
      "\n",
      "Portuguese: e esta rebeldia consciente é a razão pela qual eu , como agnóstica , posso ainda ter fé .\n",
      "English   : and this conscious defiance is why i , as an agnostic , can still have faith .\n",
      "\n",
      "Portuguese: `` `` '' podem usar tudo sobre a mesa no meu corpo . ''\n",
      "English   : you can use everything on the table on me .\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:02:20.016784Z",
     "start_time": "2025-05-15T19:02:16.530115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up the tokenizer!!\n",
    "\"\"\"\n",
    "Tokenization is the process of breaking up text, into \"tokens\".\n",
    "Download, extract, and import the saved_model:  \n",
    "\"\"\"\n",
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")\n",
    "\n",
    "tokenizers = tf.saved_model.load(model_name)"
   ],
   "id": "c7f306fa58a43401",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n",
      "\u001B[1m184801/184801\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2us/step\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: ted_hrlr_translate_pt_en_converter/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 13\u001B[0m\n\u001B[1;32m      6\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mted_hrlr_translate_pt_en_converter\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      7\u001B[0m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mget_file(\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.zip\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://storage.googleapis.com/download.tensorflow.org/models/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.zip\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     10\u001B[0m     cache_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m, cache_subdir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, extract\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     11\u001B[0m )\n\u001B[0;32m---> 13\u001B[0m tokenizers \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msaved_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:912\u001B[0m, in \u001B[0;36mload\u001B[0;34m(export_dir, tags, options)\u001B[0m\n\u001B[1;32m    910\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(export_dir, os\u001B[38;5;241m.\u001B[39mPathLike):\n\u001B[1;32m    911\u001B[0m   export_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(export_dir)\n\u001B[0;32m--> 912\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mload_partial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroot\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:1016\u001B[0m, in \u001B[0;36mload_partial\u001B[0;34m(export_dir, filters, tags, options)\u001B[0m\n\u001B[1;32m   1011\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tags \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(tags, \u001B[38;5;28mset\u001B[39m):\n\u001B[1;32m   1012\u001B[0m   \u001B[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001B[39;00m\n\u001B[1;32m   1013\u001B[0m   \u001B[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001B[39;00m\n\u001B[1;32m   1014\u001B[0m   tags \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mflatten(tags)\n\u001B[1;32m   1015\u001B[0m saved_model_proto, debug_info \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m-> 1016\u001B[0m     \u001B[43mloader_impl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_saved_model_with_debug_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1018\u001B[0m loader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1019\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(saved_model_proto\u001B[38;5;241m.\u001B[39mmeta_graphs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m   1020\u001B[0m     saved_model_proto\u001B[38;5;241m.\u001B[39mmeta_graphs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mHasField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject_graph_def\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/loader_impl.py:59\u001B[0m, in \u001B[0;36mparse_saved_model_with_debug_info\u001B[0;34m(export_dir)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mparse_saved_model_with_debug_info\u001B[39m(export_dir):\n\u001B[1;32m     47\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m   saved_model \u001B[38;5;241m=\u001B[39m \u001B[43mparse_saved_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m   debug_info_path \u001B[38;5;241m=\u001B[39m file_io\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m     62\u001B[0m       path_helpers\u001B[38;5;241m.\u001B[39mget_debug_dir(export_dir),\n\u001B[1;32m     63\u001B[0m       constants\u001B[38;5;241m.\u001B[39mDEBUG_INFO_FILENAME_PB)\n\u001B[1;32m     64\u001B[0m   debug_info \u001B[38;5;241m=\u001B[39m graph_debug_info_pb2\u001B[38;5;241m.\u001B[39mGraphDebugInfo()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/loader_impl.py:119\u001B[0m, in \u001B[0;36mparse_saved_model\u001B[0;34m(export_dir)\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot parse file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_to_pbtxt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 119\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[1;32m    120\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSavedModel file does not exist at: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexport_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    121\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mconstants\u001B[38;5;241m.\u001B[39mSAVED_MODEL_FILENAME_PBTXT\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    122\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstants\u001B[38;5;241m.\u001B[39mSAVED_MODEL_FILENAME_PB\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m saved_model\n",
      "\u001B[0;31mOSError\u001B[0m: SavedModel file does not exist at: ted_hrlr_translate_pt_en_converter/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "597f489f0d43b036"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
